---
title: "Creating bias-corrected time series of ocean temperature"
author: "Kelly Ortega-Cisneros, Denisse Fierro-Arcos"
date: "2024-10-24"
output: pdf_document
---

# Background
In this notebook, we apply the bias correction workflow described in [Ortega-Cisneros et al. (2024)](https://doi.org/10.22541/essoar.171587234.44707846/v1). We use the Southern Benguela ecosystem model as an example.  

All data used here, with the exception of the regional boundaries, can be downloaded from the [FishMIP Input Explorer app](http://rstudio.global-ecosystem-model.cloud.edu.au/shiny/FishMIP_Input_Explorer/). The `parquet` files can be downloaded from the "Model outputs against observations" tab, while the `zarr` file comes from the "GFDL model outputs" tab.  

Note that the regional boundaries and `parquet` files are included under the `data` folder of this repository. However, you will need to download the `zarr` files for the **Southern Benguela** region from the app before running this notebook. The data is downloaded as a compressed folder (`zip`) containing four files. Remember to unzip the folder before running this script. This folder was not included in this repository due to its large size.
  
# Loading relevant libraries
  
```{r setup, include=FALSE}
library(nanoparquet)
library(dplyr)
library(Rarr)
library(tidyr)
library(terra)
library(sf)
library(ggplot2)
library(lubridate)
library(cowplot)
```
  
# Loading relevant files
We use the southern Benguela model as an example, but you can replace it with data for any regional model available via the FishMIP Shiny app. You need to ensure that files are downloaded and stored in the `data` folder of this repository prior to running this script.  
  
```{r}
# Temperature data from GFDL
sb_gfdl <- file.path(
  "../data",
  "gfdl-mom6-cobalt2_obsclim_thetao_15arcmin_southern-benguela_mthly_clim_mean_1981_2010.parquet") |> 
  read_parquet()

# Temperature data from WOA
sb_woa <- file.path(
  "../data",
  "regridded_woa_southern-benguela_month_clim_mean_temp_1981-2010.parquet") |> 
  read_parquet()

# Area of grid cells
sb_areacello <- file.path(
  "../data",
  "gfdl-mom6-cobalt2_areacello_15arcmin_southern-benguela_fixed.parquet") |> 
  read_parquet() |> 
  #Selecting relevant columns
  select(lat:vals) |> 
  rename(area = vals)

# Depth of grid cells
sb_depth <- file.path(
  "../data",
  "gfdl-mom6-cobalt2_obsclim_deptho_15arcmin_southern-benguela_fixed.parquet") |> 
  read_parquet() 

# Regional model boundaries
benguela <- st_read("../data/model_regions_v3_geo3.shp")
```
  
Finally, we will define the location of the `zarr` folder. Remember, you must first download this folder from the [FishMIP Input Explorer app](http://rstudio.global-ecosystem-model.cloud.edu.au/shiny/FishMIP_Input_Explorer/) and uncompressed it in the `data` folder included in this repository before you can run the chunk below.   
  
```{r}
sb_temp_zarr_path <- file.path(
  "../data", paste0("gfdl-mom6-cobalt2_obsclim_thetao_15arcmin_southern-",
                    "benguela_monthly_1961_2010.zarr"))
```
  
## Exploring `parquet` file contents
You can use the `nanoparquet` package to explore the contents of the parquet files as shown below. This is useful to understand the structure of the data and the column types. Alternatively, you can use the `str()` function from base R or `glimpse` from `dplyr` to get a summary of the data.  
  
```{r}
parquet_column_types(sb_gfdl)
```

# Visualising temperature data
Plotting temperature data for the upper most layer from GFDL monthly climatology file.
  
```{r }
sb_gfdl |>
  filter(depth == min(depth)) |>
  #Converting months to factor and ordering them prior to plotting
  mutate(month = factor(month, levels = month.name, ordered = T)) |>
  ggplot(aes(lon, lat, fill = vals)) +
  geom_tile()+
  scale_fill_viridis_c(option = "inferno")+
  facet_wrap(~month)
```
  
The plot shows the monthly climatology (1981-2010) of sea surface temperature for the southern Benguela region from the GFDL model. Warmer colours indicate higher temperatures. The warmest months are January to March.  
  
# Processing GFDL monthly climatologies for temperature
Currently, the depth file includes the depth from the surface to the depth bin, so we will calculate the height of the depth bins. We do this because we need to calculate the volume of the grid cell to use as a weight when calculating the weighted mean for temperature.  

```{r}
depth_bins <- sb_gfdl |> 
  filter(depth <= 500) |> 
  distinct(depth) |> 
  #Calculating the difference between each depth bin to get the height of the
  #grid cell
  mutate(depth_height = depth-lag(depth, default = 0))

#Checking result
head(depth_bins)
```
  
The next step is calculating the climatologies between 1981 and 2010.
  
```{r}
# Calculating GFDL climatologies from 1981-2010
sb_gfdl_clims <- sb_gfdl |>
  #Keeping relevant columns only
  select(lat:vals) |> 
  rename(temperature = vals) |>
  #the maximum depth of the southern Benguela Atlantis model is 500 m
  filter(depth <= 500) |>
  drop_na(temperature) |>
  #Defining depth categories for the southern Benguela Atlantis model
  mutate(layer = case_when(depth < 51 ~ 1, depth > 51 & depth < 101 ~ 2, 
                           depth > 100 & depth < 301 ~ 3, depth > 300 ~ 4)) |>
  #Adding height of grid cell
  left_join(depth_bins, by = "depth") |> 
  #Adding area of grid cell
  left_join(sb_areacello, by = c("lat", "lon")) |>
  #Calculate volume of grid cell
  mutate(volume = depth_height*area) 

#Checking result
head(sb_gfdl_clims)
```
  
Next, we will turn the above data frame into a grid, which will then be used to create a mask of the different subregions(polygons) of the Southern Benguela region.  
  
```{r}
#Create raster from data frame
ras <-  sb_gfdl_clims |>
  ungroup() |>  
  #A single date and layer is needed as a sample
  filter(layer == min(layer) & month == min(month)) |> 
  #Only these three columns are needed to create a raster
  select(lon, lat, area) |> 
  #Create raster
  rast(type = "xyz", crs = "epsg:4326")

#Check result
plot(ras)
```
  
Now we have a grid of our model, which we can use to rasterise the shapefile of the Southern Benguela. We are interested in getting information about the subregions contained within Southern Benguela. This information is contained in the `number` column of the shapefile.  
  
```{r}
#Create raster mask
cb_mask <- rasterize(benguela, ras, field = "number", fun = max, 
                     background = NA) |> 
  #Transform to data frame
  as.data.frame(xy = T) |> 
  rename(lon = x, lat = y)

#Check results
cb_mask |> 
  ggplot(aes(lon, lat, fill = factor(number)))+
  geom_raster()
```
  
The result is a gridded product that contains the 18 different subregions contained within the Southern Benguela region (numbered from 0 to 17). We can now add this information to our monthly climatology data.  
  
```{r}
#Add information about subregion
sb_gfdl_clims <- sb_gfdl_clims |>
  left_join(cb_mask, by = c("lat", "lon"))

#Calculate the weighted mean for temperature per month, per depth group and subregion
sb_gfdl_summaries <- sb_gfdl_clims |>
  group_by(layer, month, number)|>
  #Using volume as weights in mean calculation
  summarise(w_temp_gfdl = weighted.mean(temperature, volume, na.rm = TRUE)) |> 
  #Transforming month column to factor
  mutate(month = factor(month, levels = month.name)) |>
  arrange(as.numeric(number), month)

#Plotting results
sb_gfdl_summaries |> 
  ggplot(aes(month, w_temp_gfdl, color = factor(number)))+
  geom_line(aes(group = number))+
  #Subplot by depth layer
  facet_wrap(~layer)+
  theme(axis.text.x = element_text(angle = 45),
        axis.title.x = element_blank())
```
  
# Processing WOA monthly climatologies for temperature
We will now follow the same process with the WOA data.  
  
```{r}
#Plotting temperature data for the upper most layer from WOA climatology
sb_woa |>
  filter(depth == min(depth)) |>
  #Converting months to factor and ordering them prior to plotting
  mutate(month = factor(month, levels = month.name, ordered = T)) |>
  ggplot(aes(lon, lat, fill = vals)) +
  geom_tile()+
  scale_fill_viridis_c(option = "inferno")+
  facet_wrap(~month)
```
  
Broad scale patterns are similar to the GFDL monthly climatologies. In both cases, the warmest months are between January and April.  
  
```{r}
# Calculating WOA climatologies from 1981-2010 for the realm of this model
sb_woa_summaries <- sb_woa |>
  #Keeping relevant columns only
  select(lat:vals) |> 
  rename(temperature = vals) |>
  #the maximum depth of the southern Benguela Atlantis model is 500 m
  filter(depth <= 500) |>
  #Defining depth categories for the southern Benguela Atlantis model
  mutate(layer = case_when(depth < 51 ~ 1, depth > 51 & depth < 101 ~ 2, 
                           depth > 100 & depth < 301 ~ 3, depth > 300 ~ 4)) |>
  #Adding height of grid cell
  left_join(depth_bins, by = "depth") |> 
  #Adding area of grid cell
  left_join(sb_areacello, by = c("lat", "lon")) |>
  #Adding information about Southern Benguela subregions 
  left_join(cb_mask, by = c("lat", "lon")) |>
  #Calculate volume of grid cell
  mutate(volume = depth_height*area) |> 
  #Excludes grid cells that are not present in GFDL
  drop_na(volume, temperature) |> 
  group_by(layer, month, number) |>
  #Using area as weights in mean calculation
  summarise(w_temp_woa = weighted.mean(temperature, volume, na.rm = TRUE)) |>
  #Transforming month column to factor
  mutate(month = factor(month, levels = month.name)) |>
  arrange(number, month)

#Plotting results
sb_woa_summaries |> 
  ggplot(aes(month, w_temp_woa, color = factor(number)))+
  geom_line(aes(group = number))+
  #Subplot by depth layer
  facet_wrap(~layer)+
  theme(axis.text.x = element_text(angle = 45),
        axis.title.x = element_blank())
```
  
The WOA data reaches a higher temperature towards the beginning of the year for the first two depth layers than GFDL. The opposite is true for the two deepest layers.   
  
## Exploring monthly temperature data from GFDL
This information is contained within the `zarr` folder, which you need to download and uncompress to the `data` folder of this repository **before** you can continue running this script.   
  
```{r}
zarr_overview(sb_temp_zarr_path)
```
  
This is telling us that the `zarr` folder contains the following variables: `depth_bin_m` (depth in meters), `lat`, `lon` (coordinates), `thetao` (temperature of the water column), and `time`.  
  
We can now load the data as shown below.  
  
## Loading data

To load the data, we will need to add the variable name to the end of the `zarr` path we defined at the beginning of this notebook.  
  
```{r}
temp_data <- read_zarr_array(file.path(sb_temp_zarr_path, "thetao"))
depth <- read_zarr_array(file.path(sb_temp_zarr_path, "depth_bin_m"))
lat <- read_zarr_array(file.path(sb_temp_zarr_path, "lat"))
lon <- read_zarr_array(file.path(sb_temp_zarr_path, "lon"))
time <- read_zarr_array(file.path(sb_temp_zarr_path, "time"))
```

## Checking dimensions of temperature data

```{r}
dim(temp_data)
```
  
The temperature data has 600 timesteps (`time`), 35 depth levels (`depth_bin_m`), 36 grid cells along latitude (`lat`) and 55 grid cells along longitude (`lon`).  
  
We can now plot the first timestep and depth bin.  
  
```{r}
image(temp_data[1,1,,])
```
  
This map does not look right. The shape is not correct and the axes do not contain information about coordinates. We need to process this data a little more.  
  
## Creating a data frame from all components
It is important to check dimensions of dataset. Note that dimensions need to match the order of dimensions in the temperature data. That is 600 timesteps (`time`), 35 depth levels (`depth_bin_m`), 36 grid cells along latitude (`lat`) and 55 grid cells along longitude (`lon`).  
  
```{r}
#We will create a grid with time, depth and coordinates
temp_sb <- cbind(expand.grid(time, depth, lat, lon), 
                 #finally add temperature
                 val = as.vector(temp_data))

#Rename the columns to reflect their contents
names(temp_sb) <- c("time", "depth", "lat", "lon", "temperature")

#Plotting result for first time step and depth
temp_sb |> 
  filter(time == min(time) & depth == min(depth)) |> 
  ggplot(aes(lon, lat, fill = temperature))+
  geom_tile()+
  scale_fill_viridis_c(option = "inferno")
```
  
This looks exactly as we need it to be. We can now calculate the weighted temperature for every timestep in our dataset.  
  
## Calculate monthly weighted temperature means
  
```{r}
#Process data from GFDL obsclim 
sb_gfdl_box <- temp_sb |> 
  #the maximum depth of the southern Benguela Atlantis model is 500 m
  filter(depth <= 500) |> 
  drop_na(temperature) |>
  #Transforming date column to date format
  mutate(date = as.Date("1961-01-01") %m+% months(round(time/30.417, 0))) |>
  #Defining depth categories for the southern Benguela Atlantis model
  mutate(layer = case_when(depth < 51 ~ 1, depth > 51 & depth < 101 ~ 2, 
                           depth > 100 & depth < 301 ~ 3, depth > 300 ~ 4)) |>
  left_join(depth_bins, by = "depth") |> 
  #Adding area of grid cell
  left_join(sb_areacello, by = c("lat", "lon")) |>
  #Adding information about Southern Benguela subregions
  left_join(cb_mask, by = c("lat", "lon")) |>
  #Calculate volume of grid cell
  mutate(volume = depth_height*area) |> 
  #Excludes grid cells that are not present in GFDL
  drop_na(volume, temperature) |> 
  #Calculated weighted means by depth group, timestep and subregion
  group_by(layer, date, number) |>
  #Using area as weights in mean calculation
  summarise(w_temp_ts = weighted.mean(temperature, volume, na.rm = TRUE)) |>
  arrange(number, date)
 
 
#plotting weighted temperature from January 1961 to December 2010
sb_gfdl_box |>
  # filter(number == 0 & layer == 1)|>
  ggplot(aes(date, w_temp_ts, color = factor(number))) +
  geom_line(aes(group = number)) +
  #Subplot by depth layer
  facet_wrap(~layer)+
  theme(axis.text.x = element_text(angle = 45),
        axis.title.x = element_blank())
```
  
## Calculate bias corrected temperature time series 
We will join all datasets together to make bias correction easier.  
  
```{r}
#Join monthly means with monthly climatologies from GFDL and WOA
sb_temp_corr_box <- sb_gfdl_box |> 
  mutate(month = factor(month.name[month(date)])) |> 
  left_join(sb_gfdl_summaries, by = c("layer", "month", "number")) |> 
  left_join(sb_woa_summaries, by = c("layer", "month", "number")) |> 
  #Apply correction
  mutate(corrected_temp = (w_temp_ts-w_temp_gfdl)+w_temp_woa)

#Plotting results for first depth layer and first subregion
sb_temp_corr_box |> 
  ungroup() |> 
  filter(layer == min(layer) & number == min(number)) |> 
  ggplot(aes(date))+
  geom_line(aes(y = corrected_temp), linetype = "dashed", color = "red") +
  geom_line(aes(y = w_temp_ts), color = "blue")+
  theme_bw()
```
  
It appears that there may be differences larger than $1^{\circ}C$. We will calculate the difference and check the results.  
  
```{r}
#calculate differences between datasets
sb_temp_corr_box |> 
  mutate(diff = corrected_temp-w_temp_ts) |> 
  arrange(desc(abs(diff))) |> 
  #Arrange by absolute differences (from largest to smallest)
  select(!c(month, w_temp_woa, w_temp_gfdl)) |> 
  head(12)
```
  
Since differences are much larger than $1^{\circ}C$ for some subregions (over $6^{\circ}C$ in subregion 3), we recommend that the bias corrected temperature (`corrected_temp`) is used to force this ecosystem model.  
  


